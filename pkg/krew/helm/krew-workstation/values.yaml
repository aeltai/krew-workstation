# Default values for krew-workstation
# Deploys the krew-backend service + UI extension for Rancher Dashboard
# Target: management cluster (local) - where Rancher UI runs

replicaCount: 1

# Extension catalog - register repo so Krew appears in Extensions UI
catalog:
  createClusterRepo: false  # Set true to add the extension repo to Rancher catalog
  name: krew-workstation
  # Use url for Helm/GitHub Pages repo, or gitRepo+gitBranch for Git
  url: ""  # e.g. https://aeltai.github.io/krew-workstation-charts
  gitRepo: ""  # e.g. https://github.com/aeltai/krew-workstation
  gitBranch: main
  refreshInterval: 0

# Bootstrap Job - creates ClusterRepo on install (adds extension catalog)
bootstrap:
  enabled: false  # Set true to auto-register catalog on install
  image:
    repository: bitnami/kubectl
    tag: "latest"

# Meta proxy - register backend with Rancher's proxy allow list (ProxyEndpoint) so /meta/proxy/... works.
# Same mechanism as node-driver / UI extensions; no manual Settings needed.
metaProxy:
  enabled: true
  # backendHost: optional override; default is <release-fullname>.<namespace>.svc (e.g. krew-workstation.krew-workstation.svc)
  backendHost: ""

# UI extension - loads the Krew Workstation UI in Rancher Dashboard
uiPlugin:
  enabled: true
  # Deploy UIPlugin to cattle-ui-plugin-system (where Rancher expects extensions)
  namespace: cattle-ui-plugin-system
  version: "0.1.0"
  # URL to extension JS bundle (must be built and published)
  # e.g. https://raw.githubusercontent.com/aeltai/ui-plugin-examples/main/extensions/krew-plugin-manager/0.1.0
  endpoint: "https://raw.githubusercontent.com/aeltai/krew-workstation/main/extensions/krew/0.1.0"
  noCache: true
  noAuth: false
  metadata:
    catalog.cattle.io/display-name: Krew Workstation
    catalog.cattle.io/kube-version: ">= 1.16.0-0"
    catalog.cattle.io/rancher-version: ">= 2.10.0-0"
    catalog.cattle.io/ui-extensions-version: ">= 3.0.0 < 4.0.0"

image:
  # Use Docker Hub (aeltai/krew-workstation) or set to ghcr.io/owner/krew-workstation if you push there
  repository: aeltai/krew-workstation
  # Use Always to avoid Helm conflict with Rancher (Rancher often sets imagePullPolicy on managed apps)
  pullPolicy: Always
  tag: "latest"

imagePullSecrets: []

nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  annotations: {}
  name: ""

podAnnotations: {}

# Run as non-root (UID 1000) so cluster Pod Security accepts the pod. Image has /opt/krew and /opt/krew-workstation chown 1000:1000.
podSecurityContext:
  runAsNonRoot: true
  runAsUser: 1000
  fsGroup: 1000

securityContext:
  allowPrivilegeEscalation: false
  capabilities:
    drop:
      - ALL
  readOnlyRootFilesystem: false
  runAsUser: 1000

service:
  type: ClusterIP
  port: 3000

ingress:
  enabled: false
  # host: override for path /krew-api (default: rancher.publicHost). Enable so terminal WebSocket works at wss://<host>/krew-api.
  host: ""
  className: ""
  annotations: {}
  tls: []

resources:
  limits:
    memory: 512Mi
  requests:
    cpu: 100m
    memory: 256Mi

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 3
  targetCPUUtilizationPercentage: 80  # used when autoscaling.enabled=true

# Rancher connection - backend fetches kubeconfig from Rancher API
rancher:
  # URL to Rancher API (from within cluster, use rancher.cattle-system.svc or your ingress)
  url: "https://rancher.cattle-system.svc"
  # REQUIRED for "Connect to the cluster" / kubeconfig sync: the host users use in the browser (no https://).
  # Without this, backend uses internal URL and Rancher returns 401 for browser tokens.
  # Example: rancher.35.157.202.39.sslip.io
  publicHost: ""
  # Optional: bearer token for backend-initiated calls (avoids 401; use if you prefer not to set publicHost)
  token: ""
  # Optional: use an existing Secret for token and public host (avoids putting secrets in values/CLI)
  existingSecret:
    name: ""           # e.g. krew-workstation-rancher
    tokenKey: token
    publicHostKey: publicHost

# Persistent volume for krew plugins (survives pod restarts)
persistence:
  enabled: true
  storageClass: ""
  size: 1Gi


nodeSelector: {}

tolerations: []

affinity: {}
